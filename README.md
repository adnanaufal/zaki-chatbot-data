# ğŸ¤– ZAKI - Hybrid RAG-Based Zakat Consultation Chatbot

![Python](https://img.shields.io/badge/Python-3.10-blue?logo=python)
![RAG](https://img.shields.io/badge/LLM-RAG-orange?logo=openai)
![License](https://img.shields.io/badge/License-MIT-green)
![Status](https://img.shields.io/badge/Status-Development-yellow)

**ZAKI** is an intelligent chatbot for **zakat information & consultation Islamic**.  
Powered by **Hybrid Retrieval-Augmented Generation (RAG)** with a **knowledge base** from the **Qurâ€™an** and official BAZNAS documents, ZAKI can answer questions with **high accuracy, trusted sources, and automated zakat calculations**.

---

## âœ¨ Key Features
- ğŸ” **Hybrid Search** â€” Combines *semantic search* and *keyword search* for more relevant results.
- ğŸ“š **Official Knowledge Base** â€” Sources from the Qurâ€™an (translation), MUI fatwas, and official BAZNAS documents.
- ğŸ“Š **Automatic Zakat Calculator** â€” Instantly calculates zakat for wealth, trade, agriculture, etc.
- ğŸŒ **Indonesian & Islamic Context** â€” NLP model optimized for Bahasa Indonesia and zakat terminology.
- ğŸ›¡ **Safe Content** â€” Source filtering & validation to ensure compliance with Islamic principles.
- âš¡ **Web Integration** â€” Ready to integrate into the BAZNAS website.

---

## ğŸ— Architecture
- **Retriever:** FAISS + BM25
- **LLM Reranker:** IndoBERT + Cross-Encoder
- **Generator:** OpenAI / Local LLM
- **Knowledge Store:** Supabase PostgreSQL (embeddings + metadata)

---

## ğŸ“‚ Dataset
This project uses two main datasets:

| Dataset                | Description |
|------------------------|-------------|
| `quran_zaki_rows.csv`  | Qurâ€™anic verses related to zakat (translation & references) |
| `baznas_docs_rows.csv` | Regulatory documents, zakat guidelines, MUI fatwas, and official BAZNAS data |

The datasets are embedded using **IndoBERT**.

---

## ğŸ“Š Evaluation
The model is evaluated using **RAGAS** with the following metrics:
- **Faithfulness** â€” Answers are consistent with the retrieved sources.
- **Answer Relevancy** â€” Answers are relevant to the given question.
- **Context Recall** â€” The retrieved context is sufficiently complete.
- **Context Precision** â€” The retrieved context is highly relevant.

---

## ğŸ“Š Detailed Evaluation Method (Upcoming)
System evaluation is conducted using **[RAGAS](https://github.com/explodinggradients/ragas)** (Retrieval-Augmented Generation Assessment Suite) to objectively measure RAG system quality.

### ğŸ“ Metrics Used
1. **Faithfulness**  
   Measures how well the answer aligns with the retrieved context.  
   *Method:* Compares the answer content with retrieved document chunks to detect hallucinations.

2. **Answer Relevancy**  
   Measures the relevance of the answer to the userâ€™s question.  
   *Method:* Embedding similarity between question and answer.

3. **Context Recall**  
   Measures the completeness of the retrieved context from the knowledge base.  
   *Method:* Compares retrieved context to the ground truth context.

4. **Context Precision**  
   Measures the accuracy of the retrieved context â€” whether it is truly relevant to the question.  
   *Method:* Calculates the proportion of relevant context to total retrieved context.

5. **Answer Semantic Similarity (Optional)**  
   Measures the semantic similarity between the modelâ€™s answer and the ideal answer (*ground truth*).

---
